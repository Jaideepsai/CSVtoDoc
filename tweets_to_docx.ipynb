{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to unicode\n",
    "# input_string=\"letâ€™s be like water ðŸ˜‚\"\n",
    "# u = unicode(input_string, \"utf-8\")\n",
    "# u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emojis from text\n",
    "# import re\n",
    "\n",
    "# emoji_pattern = re.compile(\"[\"\n",
    "#                            u\"\\U0001F600-\\U0001F64F\"  \n",
    "#                            u\"\\U0001F300-\\U0001F5FF\"\n",
    "#                            u\"\\U0001F680-\\U0001F6FF\"\n",
    "#                            u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "#                            \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# u = emoji_pattern.sub(r'', u)\n",
    "# print(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to valid xml\n",
    "# def valid_xml_char_ordinal(c):\n",
    "#     codepoint = ord(c)\n",
    "#     # conditions ordered by presumed frequency\n",
    "#     return (\n",
    "#         0x20 <= codepoint <= 0xD7FF or\n",
    "#         codepoint in (0x9, 0xA, 0xD) or\n",
    "#         0xE000 <= codepoint <= 0xFFFD or\n",
    "#         0x10000 <= codepoint <= 0x10FFFF\n",
    "#         )\n",
    "\n",
    "# cleaned_string = ''.join(c for c in u if valid_xml_char_ordinal(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_3211584_batch_results.csv\n",
      "Batch_3211579_batch_results.csv\n",
      "Batch_3211581_batch_results.csv\n",
      ".DS_Store\n",
      "Batch_3211580_batch_results.csv\n",
      "Batch_3211586_batch_results (1).csv\n",
      "Batch_3211583_batch_results.csv\n",
      "Batch_3211571_batch_results.csv\n",
      "Batch_3211587_batch_results (1).csv\n",
      "Batch_3211588_batch_results.csv\n",
      "Batch_3211575_batch_results.csv\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/jaideep/Desktop/error_project/mturk tweets\"\n",
    "dirs = os.listdir( path )\n",
    "count=0;\n",
    "document = Document()\n",
    "document.add_heading('Twitter - Mturk',level=0)\n",
    "for file in dirs:\n",
    "    print file;\n",
    "    if not file.startswith('.') and file != 'Thumbs.db':\n",
    "        \n",
    "        csv=pd.read_csv(path+\"/\"+file);\n",
    "        document.add_heading('Batch - '+ file)\n",
    "        for i in range(0,len(csv)):\n",
    "            count=count+1\n",
    "            document.add_heading('Tweet-'+str(count), level=2)\n",
    "            document.add_paragraph(unicode(csv[\"Answer.tweet\"][i], \"utf-8\"))\n",
    "\n",
    "            document.add_heading('Tweet Url', level=2)\n",
    "            document.add_paragraph(str(csv[\"Answer.tweet_url\"][i]))\n",
    "\n",
    "            document.add_heading('Submitted Date-Time', level=2)\n",
    "            document.add_paragraph(str(csv[\"SubmitTime\"][i]))\n",
    "\n",
    "            document.add_heading('Duration Time', level=2)\n",
    "            document.add_paragraph(str(csv[\"WorkTimeInSeconds\"][i]))\n",
    "\n",
    "            document.add_heading('Twitter Account Name', level=2)\n",
    "            document.add_paragraph(unicode(csv[\"Answer.account_name\"][i], \"utf-8\"))\n",
    "\n",
    "            document.add_heading('Account Url', level=2)\n",
    "            document.add_paragraph(str(csv[\"Answer.account_url\"][i]))\n",
    "\n",
    "            document.add_heading('Interpretation-1', level=2)\n",
    "            document.add_paragraph(unicode(csv[\"Answer.interpretation_1\"][i], \"utf-8\"))\n",
    "            document.add_heading('Interpretation-2', level=2)\n",
    "            document.add_paragraph(unicode(csv[\"Answer.interpretation_2\"][i], \"utf-8\"))\n",
    "            document.add_heading('Interpretation-3', level=2)\n",
    "            document.add_paragraph(unicode(csv[\"Answer.interpretation_3\"][i], \"utf-8\"))\n",
    "            document.add_heading('Interpretation-4', level=2)\n",
    "            document.add_paragraph(unicode(csv[\"Answer.interpretation_4\"][i], \"utf-8\"))\n",
    "            document.add_heading('Interpretation-5', level=2)\n",
    "            document.add_paragraph(unicode(csv[\"Answer.interpretation_5\"][i], \"utf-8\"))\n",
    "            document.add_paragraph(\"*******************************----------------------------------****************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "document.save('Twitter_April27.docx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
